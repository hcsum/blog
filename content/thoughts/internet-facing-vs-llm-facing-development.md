# ğŸ§  What Should LLM-Facing Developers Know?

> If building for the internet was the mainstream in the past 20 years, building for LLMs might be the future.

Just like how web developers don't need to know the low-level implementation of TCP/IP but understand request/response and protocols like HTTPS, developers building on top of LLMs in the future might not need to know model internalsâ€”but they should know how to interact with LLMs effectively.

## ğŸ“¦ As an LLM Developer, Here's What You Should Know

### 1. Interaction Patterns: Prompt â†’ Completion / Chat

- Understand how LLMs receive input and return output (prompts and responses)
- Learn how to call common LLM APIs (OpenAI, Claude, Mistral, local models)
- Know about token limits, context windowsâ€”similar to request size limits
- Prompt Engineering = crafting good requests (like HTTP headers + body)
- Learn function calling and tool useâ€”just like defining APIs for the model to call

### 2. Conversation State & Memory

Similar to Sessions/Cookies in web:

- Manage conversation history
- Use embeddings for memory or long-term context
- Handle short-term vs long-term memory tradeoffs

### 3. Security, Cost, and Performance

- Be aware of Prompt Injection, the new "SQL injection"
- Control token usage to manage costs
- Stream outputs, cache results, and reuse context to optimize performance

### 4. LLM Capabilities and Limitations

Know what LLMs are good at:

- Text generation, summarization, question answering, parsing

And what they're not good at:

- Accurate calculations, strict logic, complex planning

> LLMs are not databases, rule engines, or reasoning machinesâ€”they are probabilistic language models.

### 5. RAG and Agent Architectures

- Understand RAG (Retrieval-Augmented Generation):
  - Chunking, embedding, vector search
- Learn the basics of agent-style systems:
  - Multi-step reasoning, tool use, task planning
  - Frameworks: LangChain, AutoGPT, ReAct

### 6. Structured Output and Parsing

- Prompt models to output in JSON/YAML/Markdown
- Use parsers or schema validators (zod, pydantic) to handle output safely

## ğŸ§© Advanced (Optional) Knowledge

- Basic understanding of how models work (Transformers, attention mechanisms)
- Learn how embeddings work and how to compute similarity (cosine, dot product)
- Study prompt patterns: Chain-of-Thought, Few-shot, ReAct
- Know key open-source models (LLaMA, Mistral, GPT series) and how to choose between them
- Try deploying local models (Ollama, LM Studio, llama.cpp) for testing and dev

# äº’è”ç½‘å¼€å‘è€… vs LLMå¼€å‘è€…ï¼šç±»æ¯”ä¸çŸ¥è¯†ä½“ç³»

äº’è”ç½‘å¼€å‘è€…å¹¶ä¸éœ€è¦æŒæ¡ç½‘ç»œåè®®çš„å…¨éƒ¨å®ç°ç»†èŠ‚ï¼Œä½†éœ€è¦ç†è§£å®ƒçš„åŸºæœ¬å·¥ä½œæ–¹å¼ã€æ¨¡å¼å’Œé™åˆ¶ï¼›åŒç†ï¼Œæœªæ¥å¦‚æœLLMæˆä¸ºåŸºç¡€è®¾æ–½çº§åˆ«çš„æŠ€æœ¯ï¼Œå¼€å‘è€…ä¹Ÿè®¸éœ€è¦æŒæ¡"é¢å‘LLMå¼€å‘"çš„åŸºæœ¬ç†å¿µå’Œæ¥å£ï¼Œè€Œä¸å¿…æŒæ¡æ¨¡å‹çš„åº•å±‚å®ç°ã€‚

## ğŸ§  é¢å‘ LLM çš„å¼€å‘è€…éœ€è¦äº†è§£çš„çŸ¥è¯†

### 1. LLM çš„ã€Œåè®®ã€ä¸ã€Œè°ƒç”¨æ¨¡å¼ã€

- ç†è§£ LLM çš„è¾“å…¥è¾“å‡ºæ¨¡å¼ï¼ˆPrompt â†’ Completion / Chatï¼‰
- ç†Ÿæ‚‰å¸¸ç”¨çš„ API è°ƒç”¨æ–¹å¼ï¼ˆå¦‚ OpenAI, Claude, Mistral, local æ¨¡å‹ç­‰ï¼‰
- äº†è§£ä¸Šä¸‹æ–‡çª—å£å¤§å°ã€token æ¦‚å¿µï¼Œç±»ä¼¼äºè¯·æ±‚åŒ…å¤§å°çš„é™åˆ¶
- æŒæ¡æ„å»ºæç¤ºè¯­çš„æŠ€å·§ï¼ˆPrompt Engineeringï¼‰ï¼Œå°±åƒæ„é€  HTTP è¯·æ±‚å¤´å’Œ Body
- ç†è§£å‡½æ•°è°ƒç”¨ / Tool calling / æ’ä»¶æœºåˆ¶ï¼Œç›¸å½“äºä¸º LLM å®šä¹‰"APIæ¥å£"

### 2. å¯¹è¯çŠ¶æ€ä¸è®°å¿†ç®¡ç†

ç±»ä¼¼ Session/Cookie çš„æœºåˆ¶ï¼ŒLLM ä¸­ä¹Ÿéœ€è¦ç»´æŠ¤ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨ï¼š

- Conversation history
- Embedding-based memory
- é•¿æœŸè®°å¿† vs çŸ­æœŸè®°å¿† çš„åˆ’åˆ†ä¸ä½¿ç”¨ç­–ç•¥

### 3. å®‰å…¨ã€æ€§èƒ½ä¸æˆæœ¬

- ç†è§£ prompt injectionï¼ˆç›¸å½“äº SQL æ³¨å…¥ï¼‰
- é™åˆ¶ token ä½¿ç”¨ï¼Œæ§åˆ¶æˆæœ¬
- ä½¿ç”¨æµå¼è¾“å‡ºã€ç¼“å­˜é‡å¤è°ƒç”¨ç­‰æ‰‹æ®µä¼˜åŒ–æ€§èƒ½

### 4. LLM çš„èƒ½åŠ›è¾¹ç•Œä¸è¡Œä¸ºæ¨¡å‹

- å“ªäº›ä»»åŠ¡é€‚åˆ LLMï¼ˆç”Ÿæˆã€æ‘˜è¦ã€å¯¹è¯ã€ç†è§£ã€ç»“æ„åŒ–è¾“å‡ºç­‰ï¼‰
- å“ªäº›ä»»åŠ¡ä¸é€‚åˆï¼ˆç²¾ç¡®è®¡ç®—ã€ä¸¥æ ¼é€»è¾‘æ¨ç†ã€å¤šæ­¥å¤æ‚è§„åˆ’ï¼‰
- LLM å¹¶ä¸æ˜¯æ•°æ®åº“ã€è§„åˆ™å¼•æ“ã€å›¾å½¢å¼•æ“â€”â€”äº†è§£å®ƒæ˜¯ä¸€ä¸ªæ¦‚ç‡è¯­è¨€æ¨¡å‹

### 5. RAG ä¸ Agent æ¶æ„

- ç†è§£ RAGï¼ˆRetrieval-Augmented Generationï¼‰ï¼š
  - å¦‚ä½•ç»“åˆçŸ¥è¯†åº“ã€embeddingã€æœç´¢
  - chunkingã€å‘é‡æœç´¢çš„ç­–ç•¥
- åˆæ­¥äº†è§£ Agent æ¶æ„ï¼š
  - å¤šè½®å†³ç­–ã€å·¥å…·ä½¿ç”¨ã€è§„åˆ’ä¸æ‰§è¡Œ
  - LangChain, AutoGPT, ReAct ç­‰ agent æ¡†æ¶çš„åŸºæœ¬æ€æƒ³

### 6. ç»“æ„åŒ–è¾“å‡ºä¸è§£æ

- ä½¿ç”¨æ ¼å¼åŒ–æç¤ºè¾“å‡º JSON/YAML/Markdown ç­‰
- æ­é… parserã€schema æ ¡éªŒå™¨ï¼ˆå¦‚ zod, pydanticï¼‰è¿›è¡Œç»“æ„åŒ–ç†è§£

## ğŸ§© è¿›é˜¶å¼€å‘è€…å¯ä»¥äº†è§£çš„éƒ¨åˆ†

- ç®€è¦äº†è§£æ¨¡å‹ç»“æ„ï¼ˆtransformer æœºåˆ¶ã€æ³¨æ„åŠ›æœºåˆ¶ã€finetune vs pretrainï¼‰
- ç†è§£ embedding çš„æ„ä¹‰å’Œç›¸ä¼¼åº¦åº¦é‡ï¼ˆcosine, dot productï¼‰
- åŸºç¡€çš„ prompt è®¾è®¡æ¨¡å¼ï¼ˆå¦‚ Chain-of-Thought, Few-shot, ReActï¼‰
- ç†Ÿæ‚‰å¸¸ç”¨å¼€æ”¾æ¨¡å‹ï¼ˆLLaMA, Mistral, Claude, GPT ç³»åˆ—ï¼‰çš„ä¼˜åŠ£å’Œé€‰å‹å»ºè®®
- éƒ¨ç½²æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚ Ollama, LM Studio, llama.cppï¼‰ç”¨äºå¼€å‘å’Œæµ‹è¯•1
