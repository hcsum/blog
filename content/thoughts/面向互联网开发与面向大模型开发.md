# 互联网开发者 vs LLM开发者：类比与知识体系

互联网开发者并不需要掌握网络协议的全部实现细节，但需要理解它的基本工作方式、模式和限制；同理，未来如果LLM成为基础设施级别的技术，开发者也许需要掌握"面向LLM开发"的基本理念和接口，而不必掌握模型的底层实现。

## 🧠 面向 LLM 的开发者需要了解的知识

### 1. LLM 的「协议」与「调用模式」

- 理解 LLM 的输入输出模式（Prompt → Completion / Chat）
- 熟悉常用的 API 调用方式（如 OpenAI, Claude, Mistral, local 模型等）
- 了解上下文窗口大小、token 概念，类似于请求包大小的限制
- 掌握构建提示语的技巧（Prompt Engineering），就像构造 HTTP 请求头和 Body
- 理解函数调用 / Tool calling / 插件机制，相当于为 LLM 定义"API接口"

### 2. 对话状态与记忆管理

类似 Session/Cookie 的机制，LLM 中也需要维护上下文，使用：

- Conversation history
- Embedding-based memory
- 长期记忆 vs 短期记忆 的划分与使用策略

### 3. 安全、性能与成本

- 理解 prompt injection（相当于 SQL 注入）
- 限制 token 使用，控制成本
- 使用流式输出、缓存重复调用等手段优化性能

### 4. LLM 的能力边界与行为模型

- 哪些任务适合 LLM（生成、摘要、对话、理解、结构化输出等）
- 哪些任务不适合（精确计算、严格逻辑推理、多步复杂规划）
- LLM 并不是数据库、规则引擎、图形引擎——了解它是一个概率语言模型

### 5. RAG 与 Agent 架构

- 理解 RAG（Retrieval-Augmented Generation）：
  - 如何结合知识库、embedding、搜索
  - chunking、向量搜索的策略
- 初步了解 Agent 架构：
  - 多轮决策、工具使用、规划与执行
  - LangChain, AutoGPT, ReAct 等 agent 框架的基本思想

### 6. 结构化输出与解析

- 使用格式化提示输出 JSON/YAML/Markdown 等
- 搭配 parser、schema 校验器（如 zod, pydantic）进行结构化理解

## 🧩 进阶开发者可以了解的部分

- 简要了解模型结构（transformer 机制、注意力机制、finetune vs pretrain）
- 理解 embedding 的意义和相似度度量（cosine, dot product）
- 基础的 prompt 设计模式（如 Chain-of-Thought, Few-shot, ReAct）
- 熟悉常用开放模型（LLaMA, Mistral, Claude, GPT 系列）的优劣和选型建议
- 部署本地模型（如 Ollama, LM Studio, llama.cpp）用于开发和测试1
